{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadFile(dataPath,labelPath):\n",
    "    dataList = []\n",
    "    labelList= []\n",
    "    #打开文件：以二进制读模式、utf-8格式的编码方式打开\n",
    "    frData = open(dataPath)\n",
    "    frLabel = open(labelPath)\n",
    "    dataRecord = frData.read()\n",
    "    labelRecord = frLabel.read()\n",
    "    # print(record)\n",
    "    frData.close()\n",
    "    frLabel.close()\n",
    "    #按照行转换为一维表即包含各行作为元素的列表，分隔符有'\\r', '\\r\\n', \\n'\n",
    "    dataRecordList = dataRecord.splitlines()\n",
    "    labelRecordList=labelRecord.splitlines()\n",
    "    #逐行遍历：行内字段按'\\t'分隔符分隔，转换为列表\n",
    "    for line in dataRecordList:\n",
    "        if line.strip():\n",
    "            a=line.split('\\t')\n",
    "            a.pop()\n",
    "            a=list(map(float, a))\n",
    "            dataList.append(a)\n",
    "    for line in labelRecordList:\n",
    "            if line.strip():\n",
    "                a=line.split()\n",
    "                # a.pop()\n",
    "                a=list(map(float, a))\n",
    "                if a[0]!=0:\n",
    "                    labelList.append(1)\n",
    "                else:\n",
    "                    labelList.append(0)\n",
    "            # dataList.append(list(line.split(\"\\t\")))\n",
    "    #返回转换后的矩阵\n",
    "    x = np.array(dataList)\n",
    "    y = np.array(labelList)\n",
    "    return np.absolute(x),y\n",
    "    # return dataList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dataPath =\"./data.txt\"\n",
    "labelPath = \"./label.txt\"\n",
    "tx,ty=loadFile(dataPath,labelPath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(len(tx[0]))\n",
    "print(len(tx),len(ty))\n",
    "print(ty[:100])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        [(None, 300)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_14 (Embedding)     (None, 300, 256)          256000    \n",
      "_________________________________________________________________\n",
      "bgru_1 (Bidirectional)       (None, 300, 256)          296448    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 300, 256)          0         \n",
      "_________________________________________________________________\n",
      "bgru_2 (Bidirectional)       (None, 300, 256)          296448    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 300, 256)          0         \n",
      "_________________________________________________________________\n",
      "dense1 (TimeDistributed)     (None, 300, 1)            257       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 300, 1)            0         \n",
      "_________________________________________________________________\n",
      "reshape_11 (Reshape)         (None, 1, 300)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 1, 1)              0         \n",
      "_________________________________________________________________\n",
      "average_1 (GlobalAveragePool (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 849,153\n",
      "Trainable params: 849,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.engine.base_layer import Layer, InputSpec\n",
    "from keras.backend import dropout\n",
    "from keras.layers import GRU, Bidirectional, Dropout, TimeDistributed, Dense, Activation, GlobalAveragePooling1D, \\\n",
    "    Reshape, MaxPooling3D, MaxPooling1D\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "# from sklearn.model_selection import train_test_split\n",
    "class NonMasking(Layer):\n",
    "    \"\"\"\n",
    "\tNon Masking Layer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        super(NonMasking, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        input_shape = input_shape\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None, **kwargs):\n",
    "        return x\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "class KMaxPooling(Layer):\n",
    "    \"\"\"K-max pooling\n",
    "\n",
    "    k-max pooling layer that extracts the k-highest activations from a sequence and calculate average\n",
    "    base on Tensorflow backend.\n",
    "    \"\"\"\n",
    "    def __init__(self, k=1, **kwargs):\n",
    "        super(KMaxPooling,self).__init__(**kwargs)\n",
    "        self.input_spec = InputSpec(ndim = 3)\n",
    "        self.k = k\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.k, input_shape[1])\n",
    "\n",
    "    def call(self, inputs,**kwargs):\n",
    "        top_k = tf.nn.top_k(inputs, k=self.k, sorted=True, name=None)[0]\n",
    "        shifted_output = tf.transpose(top_k, [0, 2, 1])\n",
    "        return shifted_output\n",
    "\n",
    "inputs = keras.Input(shape=(300,))\n",
    "x = layers.Embedding(1000, 256)(inputs)\n",
    "# Embed each integer in a 128-dimensional vector\n",
    "# mask_1 = keras.layers.Masking(mask_value=0.0, name='mask_1')(x)\n",
    "bgru_1 = Bidirectional(GRU(units=128, activation='tanh', recurrent_activation='hard_sigmoid', return_sequences=True), name='bgru_1')(x)\n",
    "dropout_1 = Dropout(rate=0.4, name='dropout_1')(bgru_1)\n",
    "bgru_2 = Bidirectional(GRU(units=128, activation='tanh', recurrent_activation='hard_sigmoid', return_sequences=True), name='bgru_2')(dropout_1)\n",
    "dropout_2 = Dropout(rate=0.4, name='dropout_2')(bgru_2)\n",
    "dense_1 = TimeDistributed(Dense(1), name='dense1')(dropout_2)\n",
    "activation_1 = Activation('sigmoid', name='activation_1')(dense_1)\n",
    "# unmask_1 = NonMasking()(activation_1)/\n",
    "reshape_1 = Reshape((1, 300))(activation_1)\n",
    "k_max_1 = MaxPooling1D(pool_size=300,data_format='channels_first')(reshape_1)\n",
    "average_1 = GlobalAveragePooling1D(name='average_1')(k_max_1)\n",
    "# # Add a classifier\n",
    "# outputs = layers.Dense(1, activation=\"sigmoid\")(average_1)\n",
    "model = keras.Model(inputs, average_1)\n",
    "model.summary()\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        # 不再提升的关注指标\n",
    "        monitor='accuracy',\n",
    "        # 不再提升的阈值\n",
    "        min_delta=1e-3,\n",
    "        # 不再提升的轮次\n",
    "        patience=2,\n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "    # 模型路径\n",
    "    filepath='./model/model_{epoch}.h5',\n",
    "    # 是否保存最佳\n",
    "    save_best_only=True,\n",
    "    # 监控指标\n",
    "    monitor='val_accuracy',\n",
    "    # 进度条类型\n",
    "    verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\",\n",
    "                       \"Precision\",\n",
    "                       \"Recall\",\n",
    "                       \"TruePositives\",\n",
    "                       \"TrueNegatives\",\n",
    "                       \"FalsePositives\",\n",
    "                       \"FalseNegatives\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 300\n",
      "Epoch 1/10\n",
      "364/750 [=============>................] - ETA: 54:13 - loss: 0.5293 - accuracy: 0.7526 - precision: 0.7621 - recall: 0.8769 - true_positives: 12736.0000 - true_negatives: 4797.0000 - false_positives: 3975.0000 - false_negatives: 1788.0000"
     ]
    }
   ],
   "source": [
    "train_x = tx[:60000]\n",
    "train_y = ty[:60000]\n",
    "print(len(train_x),len(train_x[0]))\n",
    "\n",
    "model.fit(train_x, train_y, epochs=10, batch_size=64,validation_split=0.2)\n",
    "model.save('./BGRU/BGRU_model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 17s 1s/step - loss: 0.6901 - accuracy: 0.6136 - precision: 0.5923 - recall: 0.9693 - true_positives: 536.0000 - true_negatives: 77.0000 - false_positives: 369.0000 - false_negatives: 17.0000\n",
      "[0.6901264786720276, 0.6136136054992676, 0.5922651886940002, 0.9692586064338684, 536.0, 77.0, 369.0, 17.0]\n",
      "35340 36339\n",
      "16/16 [==============================] - 16s 1s/step - loss: 0.6866 - accuracy: 0.6807 - precision: 0.6807 - recall: 1.0000 - true_positives: 680.0000 - true_negatives: 0.0000e+00 - false_positives: 319.0000 - false_negatives: 0.0000e+00\n",
      "[0.6866385340690613, 0.6806806921958923, 0.6806806921958923, 1.0, 680.0, 0.0, 319.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "tt=int(np.random.randint(3000,8000))*10\n",
    "ttx=tt+999\n",
    "print(tt,ttx)\n",
    "test_x = tx[30000+tt:30000+ttx]\n",
    "test_y = ty[30000+tt:30000+ttx]\n",
    "results = model.evaluate(test_x, test_y, batch_size=64)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1, 3)\n",
      "tf.Tensor(\n",
      "[[[ 6]]\n",
      "\n",
      " [[12]]], shape=(2, 1, 1), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[[ 6]]\n",
      "\n",
      " [[12]]], shape=(2, 1, 1), dtype=int32)\n",
      "(2, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[[ 4,  5,  6]],\n",
    "                 [[10, 11, 12]]])\n",
    "print(x.get_shape())\n",
    "top_k = tf.nn.top_k(x, k=1, sorted=True, name=None)[0]\n",
    "print(top_k)\n",
    "shifted_output = tf.transpose(top_k, perm=[0, 2, 1])\n",
    "print(shifted_output)\n",
    "print(shifted_output.get_shape())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[[1. 2. 3. 4. 5.]]], shape=(1, 1, 5), dtype=float32)\n",
      "<keras.layers.pooling.MaxPooling1D object at 0x000001A86B3685B0>\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([1., 2., 3., 4., 5.])\n",
    "x = tf.reshape(x, [1, 1, 5])\n",
    "print(x)\n",
    "max_pool_1d = tf.keras.layers.MaxPooling1D(pool_size=2,\n",
    "strides=2, padding='valid')\n",
    "print(max_pool_1d)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dab8e41921a9804032d7b1bd163ac623c44de801f9b5a9764714bd0c64231e68"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}