{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data Cutting"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from keras import Input, Model, models\n",
    "import tensorflow as tf\n",
    "from keras.layers import GRU, Bidirectional, Dropout, TimeDistributed, Dense, Activation, GlobalAveragePooling1D, Reshape, MaxPooling1D, Multiply"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24235/24235 [00:00<00:00, 215043.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_num: 600\n",
      "test_num: 200\n",
      "validation_num: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 293765750/293765750 [00:03<00:00, 79619590.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_sum: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def DataCutting(irpath, labelpath, datafile):\n",
    "    \"\"\"数据切割\n",
    "\n",
    "    :param irpath: 待切割ir数据地址\n",
    "    :param labelpath: 待切割标签地址\n",
    "    :param datafile: 切割后数据存放文件夹\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    #切割完后存放标签的地址\n",
    "    train_label_path = datafile + '/train_label.txt'\n",
    "    test_label_path = datafile + '/test_label.txt'\n",
    "    validation_label_path = datafile + '/validation_label.txt'\n",
    "    #切割完后存放IR向量地址\n",
    "    train_IR_path = datafile + '/train_IR.txt'\n",
    "    test_IR_path = datafile + '/test_IR.txt'\n",
    "    validation_IR_path = datafile + '/validation_IR.txt'\n",
    "\n",
    "    #切割方式为每十行都把数据划分为6:2:2，分别为训练集、验证集、测试集\n",
    "    #pbar用于进度条显示\n",
    "    with tqdm(total=os.path.getsize(labelpath)) as pbar:\n",
    "        with open(labelpath, 'r') as f1:\n",
    "            train_label = open(train_label_path, 'a', encoding='UTF-8')\n",
    "            test_label = open(test_label_path, 'a', encoding='UTF-8')\n",
    "            validation_label = open(validation_label_path, 'a', encoding='UTF-8')\n",
    "            t = 0\n",
    "            train_num = 0\n",
    "            test_num = 0\n",
    "            validation_num = 0\n",
    "            for line in f1:\n",
    "                t += 1\n",
    "                pbar.update(len(line))\n",
    "                if t <= 6:\n",
    "                    train_label.write(line)\n",
    "                    train_num += 1\n",
    "                elif t <= 8:\n",
    "                    test_label.write(line)\n",
    "                    test_num += 1\n",
    "                elif t <= 10:\n",
    "                    validation_label.write(line)\n",
    "                    validation_num += 1\n",
    "                    if t == 10:\n",
    "                        t = 0\n",
    "\n",
    "            train_label.close()\n",
    "            test_label.close()\n",
    "            validation_label.close()\n",
    "            print(\"train_num: \" + str(train_num))\n",
    "            print(\"test_num: \" + str(test_num))\n",
    "            print(\"validation_num: \" + str(validation_num))\n",
    "\n",
    "    with tqdm(total=os.path.getsize(irpath)) as pbar:\n",
    "        with open(irpath, 'r') as f1:\n",
    "            train_IR = open(train_IR_path, 'a', encoding='UTF-8')\n",
    "            test_IR = open(test_IR_path, 'a', encoding='UTF-8')\n",
    "            validation_IR = open(validation_IR_path, 'a', encoding='UTF-8')\n",
    "            t = 0\n",
    "            k = 0\n",
    "            for line in f1:\n",
    "                pbar.update(len(line))\n",
    "                if t < 6:\n",
    "                    train_IR.write(line)\n",
    "                elif t < 8:\n",
    "                    test_IR.write(line)\n",
    "                elif t < 10:\n",
    "                    validation_IR.write(line)\n",
    "                if line.find('#') != -1:\n",
    "                    t += 1\n",
    "                    k += 1\n",
    "                    if t == 10:\n",
    "                        t = 0\n",
    "\n",
    "            print(\"data_sum: \" + str(k))\n",
    "\n",
    "            train_IR.close()\n",
    "            test_IR.close()\n",
    "            validation_IR.close()\n",
    "\n",
    "\n",
    "#原始数据地址\n",
    "label_path = '../data/label_Juliet2.txt'\n",
    "IR_path = '../data/data_Juliet2.txt'\n",
    "#切割后数据存放文件夹\n",
    "data_file = '../data/Juliet'\n",
    "DataCutting(IR_path, label_path, data_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Generator"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TrainDataGenerator"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def TrainDataGenerator(data_path, label_path, batch_size=64, maxlen=1000):\n",
    "    \"\"\"训练数据集生成器\n",
    "\n",
    "    :param data_path: 数据集路径\n",
    "    :param label_path: 行号标签路径\n",
    "    :param batch_size: 批次大小\n",
    "    :param maxlen: 时间步维度，即最大保留多少行号\n",
    "    :return: 一个generator,形式为([dataSet,matrixSet], labelSet)\n",
    "        dataSet:IR向量数据集\n",
    "        matrixSet:注意力矩阵\n",
    "        labelSet:行号标签\n",
    "    \"\"\"\n",
    "\n",
    "    fd = open(data_path)\n",
    "    fl = open(label_path)\n",
    "    datas = fd.readlines()\n",
    "    datas_tag = 0\n",
    "    labels = fl.readlines()\n",
    "    # print(len(datas), len(labels))\n",
    "    iter_num = int(len(labels) / batch_size)\n",
    "    print(iter_num)\n",
    "    i = 0\n",
    "    while iter_num:\n",
    "        irLine = []  #每行ir向量\n",
    "        irList = []  #ir切片向量列表\n",
    "        labelList = []  #label列表\n",
    "        vulList = []  #漏洞列表\n",
    "        matrixList = []\n",
    "        label_line = labels[i:i + batch_size]\n",
    "\n",
    "        for line in label_line:\n",
    "            line = line.strip()\n",
    "            a = line.split()\n",
    "            a = list(map(float, a))\n",
    "            if a[0] != 0:\n",
    "                vulList.append(a)\n",
    "                labelList.append(1)\n",
    "            else:\n",
    "                vulList.append(0)\n",
    "                labelList.append(0)\n",
    "\n",
    "        for vp in range(len(vulList)):\n",
    "            #先求漏洞行号标注在一个一维向量上\n",
    "            if not vulList[vp]:\n",
    "                attentionLine = [1] * maxlen\n",
    "            else:\n",
    "                attentionLine = [0] * maxlen\n",
    "                for vul in vulList[vp]:\n",
    "                    if int(vul) > maxlen:\n",
    "                        continue\n",
    "                    attentionLine[int(vul) - 1] = 1\n",
    "            #再将其转化为矩阵\n",
    "            attentionmatrix = np.diag(attentionLine)\n",
    "            matrixList.append(attentionmatrix)\n",
    "\n",
    "        while len(irList) < batch_size:\n",
    "            line = datas[datas_tag]\n",
    "            datas_tag += 1\n",
    "            #逐行遍历：行内字段按'\\t'分隔符分隔，转换为列表\n",
    "            line = line.strip()\n",
    "            a = line.split('\\t')\n",
    "            if '#' not in a[0]:\n",
    "                a = list(map(float, a))\n",
    "                irLine.append(a)\n",
    "            else:\n",
    "                x = [0 for t in range(300)]\n",
    "                while len(irLine) < maxlen:\n",
    "                    irLine.append(x)\n",
    "                irList.append(irLine)\n",
    "                irLine = []\n",
    "                continue\n",
    "\n",
    "        dataSet = np.array(irList)\n",
    "        labelSet = np.array(labelList)\n",
    "        matrixSet = np.array(matrixList)\n",
    "        # print(i)\n",
    "        # print(dataSet.ndim)\n",
    "        if dataSet.ndim != 3:\n",
    "            i += batch_size\n",
    "            iter_num -= 1\n",
    "            if iter_num == 0:\n",
    "                iter_num = int(len(labels) / batch_size)\n",
    "                datas_tag = 0\n",
    "                i = 0\n",
    "            continue\n",
    "        yield [dataSet, matrixSet], labelSet\n",
    "        i += batch_size\n",
    "\n",
    "        iter_num -= 1\n",
    "        if iter_num == 0:\n",
    "            iter_num = int(len(labels) / batch_size)\n",
    "            datas_tag = 0\n",
    "            i = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TestDataGenerator"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestDataGenerator(data_path, label_path, batch_size=64, maxlen=1000):\n",
    "    \"\"\"测试数据集生成器\n",
    "\n",
    "    :param data_path: 数据集路径\n",
    "    :param label_path: 行号标签路径\n",
    "    :param batch_size: 批次大小\n",
    "    :param maxlen: 时间步维度，即最大保留多少行号\n",
    "    :return: 一个generator,形式为([dataSet,matrixSet], labelSet,vulList)\n",
    "        dataSet:IR向量数据集\n",
    "        matrixSet:注意力矩阵\n",
    "        labelSet:行号01标签\n",
    "        vulList:行号标签\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    fd = open(data_path)\n",
    "    fl = open(label_path)\n",
    "    datas = fd.readlines()\n",
    "    labels = fl.readlines()\n",
    "    # print(len(datas), len(labels))\n",
    "    iter_num = int(len(labels) / batch_size)\n",
    "    print(iter_num)\n",
    "    datas_tag = 0\n",
    "    i = 0\n",
    "    while iter_num:\n",
    "        irLine = []  #每行ir向量\n",
    "        irList = []  #ir切片向量列表\n",
    "        labelList = []  #label列表\n",
    "        vulList = []  #漏洞列表\n",
    "        matrixList = []\n",
    "        label_line = labels[i:i + batch_size]\n",
    "\n",
    "        for line in label_line:\n",
    "            line = line.strip()\n",
    "            a = line.split()\n",
    "            a = list(map(float, a))\n",
    "            if a[0] != 0:\n",
    "                vulList.append(a)\n",
    "                labelList.append(1)\n",
    "            else:\n",
    "                vulList.append(0)\n",
    "                labelList.append(0)\n",
    "\n",
    "        for vp in range(len(vulList)):\n",
    "            #先求漏洞行号标注在一个一维向量上\n",
    "            if not vulList[vp]:\n",
    "                attentionLine = [1] * maxlen\n",
    "            else:\n",
    "                attentionLine = [0] * maxlen\n",
    "                for vul in vulList[vp]:\n",
    "                    if int(vul) > maxlen:\n",
    "                        continue\n",
    "                    attentionLine[int(vul) - 1] = 1\n",
    "            #再将其转化为矩阵\n",
    "            attentionmatrix = np.diag(attentionLine)\n",
    "            matrixList.append(attentionmatrix)\n",
    "\n",
    "        while len(irList) < batch_size:\n",
    "            line = datas[datas_tag]\n",
    "            datas_tag += 1\n",
    "            #逐行遍历：行内字段按'\\t'分隔符分隔，转换为列表\n",
    "            line = line.strip()\n",
    "            a = line.split('\\t')\n",
    "            if '#' not in a[0]:\n",
    "                a = list(map(float, a))\n",
    "                irLine.append(a)\n",
    "            else:\n",
    "                x = [0 for t in range(300)]\n",
    "                while len(irLine) < maxlen:\n",
    "                    irLine.append(x)\n",
    "                irList.append(irLine)\n",
    "                irLine = []\n",
    "                continue\n",
    "\n",
    "        dataSet = np.array(irList)\n",
    "        labelSet = np.array(labelList)\n",
    "        matrixSet = np.array(matrixList)\n",
    "        # print(i)\n",
    "        # print(dataSet.ndim)\n",
    "        if dataSet.ndim != 3:\n",
    "            i += batch_size\n",
    "            iter_num -= 1\n",
    "            if iter_num == 0:\n",
    "                iter_num = int(len(labels) / batch_size)\n",
    "                datas_tag = 0\n",
    "                i = 0\n",
    "            continue\n",
    "        yield [dataSet, matrixSet], labelSet, vulList\n",
    "        i += batch_size\n",
    "\n",
    "        iter_num -= 1\n",
    "        if iter_num == 0:\n",
    "            iter_num = int(len(labels) / batch_size)\n",
    "            datas_tag = 0\n",
    "            i = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "0 (64, 1000, 300) (64,) (64, 1000, 1000)\n",
      "1 (64, 1000, 300) (64,) (64, 1000, 1000)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [12]\u001B[0m, in \u001B[0;36m<cell line: 12>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      9\u001B[0m label_path\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../data/label_Juliet2.txt\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     10\u001B[0m data_path\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../data/data_Juliet2.txt\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m---> 12\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, ([data, attMatrix],label) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(TrainDataGenerator(train_IR_path, train_label_path, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m64\u001B[39m)):\n\u001B[0;32m     13\u001B[0m     \u001B[38;5;28mprint\u001B[39m(i, data\u001B[38;5;241m.\u001B[39mshape, label\u001B[38;5;241m.\u001B[39mshape,attMatrix\u001B[38;5;241m.\u001B[39mshape)\n",
      "Input \u001B[1;32mIn [10]\u001B[0m, in \u001B[0;36mTrainDataGenerator\u001B[1;34m(data_path, label_path, batch_size, maxlen)\u001B[0m\n\u001B[0;32m     73\u001B[0m         \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[0;32m     76\u001B[0m dataSet \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(irList)\n\u001B[1;32m---> 77\u001B[0m labelSet \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241m.\u001B[39marray(labelList)\n\u001B[0;32m     78\u001B[0m matrixSet\u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(matrixList)\n\u001B[0;32m     79\u001B[0m \u001B[38;5;66;03m# print(i)\u001B[39;00m\n\u001B[0;32m     80\u001B[0m \u001B[38;5;66;03m# print(dataSet.ndim)\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "train_IR_path = '../data/Juliet/train_IR.txt'\n",
    "test_IR_path = '../data/Juliet/test_IR.txt'\n",
    "validation_IR_path = '../data/Juliet/validation_IR.txt'\n",
    "\n",
    "train_label_path = '../data/Juliet/train_label.txt'\n",
    "test_label_path = '../data/Juliet/test_label.txt'\n",
    "validation_label_path = '../data/Juliet/validation_label.txt'\n",
    "\n",
    "label_path = '../data/label_Juliet2.txt'\n",
    "data_path = '../data/data_Juliet2.txt'\n",
    "\n",
    "for i, ([data, attMatrix], label) in enumerate(TrainDataGenerator(train_IR_path, train_label_path, batch_size=64)):\n",
    "    print(i, data.shape, label.shape, attMatrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Model Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 1000, 300)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mask_1 (Masking)                (None, 1000, 300)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bgru_1 (Bidirectional)          (None, 1000, 64)     64128       mask_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1000, 64)     0           bgru_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bgru_2 (Bidirectional)          (None, 1000, 64)     18816       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1000, 64)     0           bgru_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (TimeDistributed)        (None, 1000, 1)      65          dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "att_Matrix (InputLayer)         [(None, 1000, 1000)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 1000, 1)      0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 1000, 1000)   0           att_Matrix[0][0]                 \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 1, 1000000)   0           multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 1, 1)         0           reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "average_1 (GlobalAveragePooling (None, 1)            0           max_pooling1d[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 83,009\n",
      "Trainable params: 83,009\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Masking\n",
    "\n",
    "\n",
    "def build_model(maxlen, dropout, units):\n",
    "    \"\"\"\n",
    "\n",
    "    :param maxlen:最大时间步(最大行号)\n",
    "    :param dropout:随机让神经元停止工作的概率\n",
    "    :param units:GRU神经元数量\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=(maxlen, 300))\n",
    "    mask_1 = Masking(mask_value=0.0, name='mask_1')(inputs)\n",
    "    bgru_1 = Bidirectional(GRU(units=units,\n",
    "                               activation='tanh',\n",
    "                               recurrent_activation='sigmoid',\n",
    "                               return_sequences=True),\n",
    "                           name='bgru_1')(mask_1)\n",
    "    dropout_1 = Dropout(rate=dropout, name='dropout_1')(bgru_1)\n",
    "    bgru_2 = Bidirectional(GRU(units=units,\n",
    "                               activation='tanh',\n",
    "                               recurrent_activation='sigmoid',\n",
    "                               return_sequences=True),\n",
    "                           name='bgru_2')(dropout_1)\n",
    "    dropout_2 = Dropout(rate=dropout, name='dropout_2')(bgru_2)\n",
    "\n",
    "    dense_1 = TimeDistributed(Dense(1), name='dense1')(dropout_2)\n",
    "    activation_1 = Activation('sigmoid', name='activation_1')(dense_1)\n",
    "\n",
    "    att_Matrix_1 = Input(shape=(maxlen, maxlen), name='att_Matrix')\n",
    "    multiply_1 = Multiply(name='multiply_1')([att_Matrix_1, activation_1])\n",
    "    reshape_1 = Reshape((1, maxlen ** 2))(multiply_1)\n",
    "\n",
    "    k_max_1 = MaxPooling1D(pool_size=maxlen ** 2, data_format='channels_first')(reshape_1)\n",
    "    average_1 = GlobalAveragePooling1D(name='average_1')(k_max_1)\n",
    "\n",
    "    model = Model(inputs=[inputs, att_Matrix_1], outputs=average_1)\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(optimizer=\"adam\",\n",
    "                  loss=\"binary_crossentropy\",\n",
    "                  metrics=[\"accuracy\",\n",
    "                           \"Precision\",\n",
    "                           \"Recall\",\n",
    "                           \"TruePositives\",\n",
    "                           \"TrueNegatives\",\n",
    "                           \"FalsePositives\",\n",
    "                           \"FalseNegatives\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model(maxlen=1000, dropout=0.4, units=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "Epoch 1/4\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.7143 - accuracy: 0.5365 - precision: 0.1845 - recall: 0.1925 - true_positives: 31.0000 - true_negatives: 278.0000 - false_positives: 137.0000 - false_negatives: 130.00003\n",
      "9/9 [==============================] - 73s 7s/step - loss: 0.7143 - accuracy: 0.5365 - precision: 0.1845 - recall: 0.1925 - true_positives: 31.0000 - true_negatives: 278.0000 - false_positives: 137.0000 - false_negatives: 130.0000 - val_loss: 0.6951 - val_accuracy: 0.6625 - val_precision: 0.3636 - val_recall: 0.1212 - val_true_positives: 12.0000 - val_true_negatives: 200.0000 - val_false_positives: 21.0000 - val_false_negatives: 87.0000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66250, saving model to ./model\\model_01-0.66.h5\n",
      "Epoch 2/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\program_files\\miniconda3\\envs\\DeepLearning\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 60s 7s/step - loss: 0.7022 - accuracy: 0.6233 - precision: 0.1889 - recall: 0.1056 - true_positives: 17.0000 - true_negatives: 342.0000 - false_positives: 73.0000 - false_negatives: 144.0000 - val_loss: 0.6995 - val_accuracy: 0.6906 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_true_positives: 0.0000e+00 - val_true_negatives: 221.0000 - val_false_positives: 0.0000e+00 - val_false_negatives: 99.0000\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.66250 to 0.69063, saving model to ./model\\model_02-0.69.h5\n",
      "Epoch 3/4\n",
      "9/9 [==============================] - 58s 7s/step - loss: 0.6978 - accuracy: 0.5764 - precision: 0.2682 - recall: 0.2981 - true_positives: 48.0000 - true_negatives: 284.0000 - false_positives: 131.0000 - false_negatives: 113.0000 - val_loss: 0.6985 - val_accuracy: 0.6906 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_true_positives: 0.0000e+00 - val_true_negatives: 221.0000 - val_false_positives: 0.0000e+00 - val_false_negatives: 99.0000\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.69063\n",
      "Epoch 4/4\n",
      "9/9 [==============================] - 61s 7s/step - loss: 0.6923 - accuracy: 0.6684 - precision: 0.3729 - recall: 0.2733 - true_positives: 44.0000 - true_negatives: 341.0000 - false_positives: 74.0000 - false_negatives: 117.0000 - val_loss: 0.6895 - val_accuracy: 0.6906 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_true_positives: 0.0000e+00 - val_true_negatives: 221.0000 - val_false_positives: 0.0000e+00 - val_false_negatives: 99.0000\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.69063\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, TrainGenerator, ValidGenerator):\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            # 模型路径\n",
    "            filepath='./model/model_{epoch:02d}-{val_accuracy:.2f}.h5',\n",
    "            # 是否保存最佳\n",
    "            save_best_only=True,\n",
    "            # 监控指标\n",
    "            monitor='val_accuracy',\n",
    "            # 进度条类型\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    model.fit(TrainGenerator,\n",
    "              steps_per_epoch=9,  #每批次总步数\n",
    "              epochs=4,  #批次数\n",
    "              validation_data=ValidGenerator,  #验证集\n",
    "              validation_steps=5,  #每次验证步数\n",
    "              validation_batch_size=64,  #验证集每批次数据大小\n",
    "              verbose=1,\n",
    "              callbacks=callbacks)\n",
    "\n",
    "\n",
    "train_IR_path = '../data/Juliet/train_IR.txt'\n",
    "validation_IR_path = '../data/Juliet/validation_IR.txt'\n",
    "\n",
    "train_label_path = '../data/Juliet/train_label.txt'\n",
    "validation_label_path = '../data/Juliet/validation_label.txt'\n",
    "\n",
    "tdg = TrainDataGenerator(train_IR_path, train_label_path, batch_size=64)\n",
    "vdg = TrainDataGenerator(validation_IR_path, validation_label_path, batch_size=64)\n",
    "train_model(model, tdg, vdg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 0\n",
      "3\n",
      "[] 0 0\n",
      "[754, 143, 58, 325, 586, 283, 670, 628, 712, 456, 544, 367, 100, 15, 241, 186, 499, 411, 412, 500] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[4] 1 [5.0, 6.0, 7.0]\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 1 [12.0, 13.0, 14.0]\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[759, 581, 63, 148, 320, 675, 278, 717, 15, 451, 539, 236, 362, 105, 633, 191, 494, 406, 407, 495] 1 [6.0, 7.0, 8.0, 62.0, 63.0, 64.0, 111.0, 112.0, 113.0, 161.0, 162.0, 163.0, 210.0, 211.0, 212.0, 263.0, 264.0, 265.0, 312.0, 313.0, 314.0, 361.0, 362.0, 363.0, 410.0, 411.0, 412.0, 460.0, 461.0, 462.0, 513.0, 514.0, 515.0, 562.0, 563.0, 564.0, 615.0, 616.0, 617.0, 664.0, 665.0, 666.0, 712.0, 713.0, 714.0, 726.0, 727.0, 728.0, 775.0, 776.0, 777.0, 824.0, 825.0, 826.0, 873.0, 874.0, 875.0]\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[4] 1 [5.0, 6.0, 7.0]\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[754, 143, 58, 315, 586, 712, 670, 628, 273, 544, 231, 357, 100, 15, 456, 401, 499, 186, 402, 500] 1 [6.0, 7.0, 8.0, 56.0, 57.0, 58.0, 105.0, 106.0, 107.0, 155.0, 156.0, 157.0, 204.0, 205.0, 206.0, 257.0, 258.0, 259.0, 306.0, 307.0, 308.0, 355.0, 356.0, 357.0, 404.0, 405.0, 406.0, 454.0, 455.0, 456.0, 520.0, 521.0, 522.0, 569.0, 570.0, 571.0, 622.0, 623.0, 624.0, 671.0, 672.0, 673.0, 720.0, 721.0, 722.0, 769.0, 770.0, 771.0, 818.0, 819.0, 820.0, 867.0, 868.0, 869.0]\n",
      "[18, 19, 20, 21, 22, 23, 24, 17] 1 [18.0, 19.0, 20.0]\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[55, 56, 57, 58, 59, 60, 61, 62, 54, 53] 1 [60.0, 61.0, 62.0]\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[4] 1 [5.0, 6.0, 7.0]\n",
      "[4, 3, 5, 2, 6, 7, 8, 10, 9, 11, 14, 12, 15, 13, 16, 17, 19, 18, 20, 21] 1 [4.0, 5.0, 6.0]\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[754, 534, 143, 58, 315, 628, 712, 670, 273, 446, 231, 357, 100, 15, 586, 186, 489, 401, 402, 490] 1 [6.0, 7.0, 8.0, 56.0, 57.0, 58.0, 105.0, 106.0, 107.0, 155.0, 156.0, 157.0, 204.0, 205.0, 206.0, 257.0, 258.0, 259.0, 306.0, 307.0, 308.0, 355.0, 356.0, 357.0, 404.0, 405.0, 406.0, 454.0, 455.0, 456.0, 507.0, 508.0, 509.0, 556.0, 557.0, 558.0, 609.0, 610.0, 611.0, 671.0, 672.0, 673.0, 720.0, 721.0, 722.0, 769.0, 770.0, 771.0, 818.0, 819.0, 820.0, 867.0, 868.0, 869.0]\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[769, 315, 591, 143, 58, 273, 685, 727, 549, 231, 461, 362, 100, 15, 643, 406, 504, 186, 407, 505] 1 [6.0, 7.0, 8.0, 56.0, 57.0, 58.0, 105.0, 106.0, 107.0, 155.0, 156.0, 157.0, 204.0, 205.0, 206.0, 257.0, 258.0, 259.0, 306.0, 307.0, 308.0, 355.0, 356.0, 357.0, 410.0, 411.0, 412.0, 460.0, 461.0, 462.0, 525.0, 526.0, 527.0, 574.0, 575.0, 576.0, 627.0, 628.0, 629.0, 676.0, 677.0, 678.0, 724.0, 725.0, 726.0, 738.0, 739.0, 740.0, 787.0, 788.0, 789.0, 836.0, 837.0, 838.0, 885.0, 886.0, 887.0]\n",
      "[7, 8, 6, 9, 5, 10, 11, 12, 19, 13, 14, 16, 15, 17, 18, 20, 21, 22, 23, 24] 1 [9.0, 10.0, 11.0]\n",
      "[] 1 [12.0, 13.0, 14.0]\n",
      "TP:11 FP:1 FN:2 TN:50\n",
      "TP_l:8 FP_l:1 FN_l:5 TN_l:50\n",
      "epochs: 1\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[754, 315, 143, 58, 586, 273, 712, 670, 628, 456, 544, 231, 100, 15, 367, 411, 186, 499, 412, 500] 1 [6.0, 7.0, 8.0, 56.0, 57.0, 58.0, 105.0, 106.0, 107.0, 155.0, 156.0, 157.0, 204.0, 205.0, 206.0, 257.0, 258.0, 259.0, 306.0, 307.0, 308.0, 355.0, 356.0, 357.0, 403.0, 404.0, 405.0, 417.0, 418.0, 419.0, 467.0, 468.0, 469.0, 520.0, 521.0, 522.0, 569.0, 570.0, 571.0, 622.0, 623.0, 624.0, 671.0, 672.0, 673.0, 720.0, 721.0, 722.0, 769.0, 770.0, 771.0, 818.0, 819.0, 820.0, 867.0, 868.0, 869.0]\n",
      "[] 1 [19.0, 20.0, 21.0]\n",
      "[28, 29, 30, 31, 32, 33, 34, 35, 27, 26] 1 [28.0, 29.0, 30.0]\n",
      "[] 0 0\n",
      "[] 1 [14.0, 15.0, 16.0]\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[32, 33, 34, 35, 36, 37, 38, 39, 42, 40, 43, 41, 44, 31] 1 [34.0, 35.0, 36.0]\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[755, 315, 143, 58, 587, 671, 629, 273, 713, 457, 545, 231, 100, 15, 368, 186, 500, 412, 413, 501] 1 [6.0, 7.0, 8.0, 56.0, 57.0, 58.0, 105.0, 106.0, 107.0, 155.0, 156.0, 157.0, 204.0, 205.0, 206.0, 257.0, 258.0, 259.0, 306.0, 307.0, 308.0, 355.0, 356.0, 357.0, 418.0, 419.0, 420.0, 468.0, 469.0, 470.0, 521.0, 522.0, 523.0, 570.0, 571.0, 572.0, 623.0, 624.0, 625.0, 672.0, 673.0, 674.0, 721.0, 722.0, 723.0, 770.0, 771.0, 772.0, 819.0, 820.0, 821.0, 868.0, 869.0, 870.0]\n",
      "[] 0 0\n",
      "[13, 14, 15, 16, 17, 18, 19, 21, 20, 12] 1 [13.0, 14.0, 15.0]\n",
      "[] 0 0\n",
      "[55, 56, 57, 58, 59, 60, 61, 54, 53] 1 [63.0, 64.0, 65.0]\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[754, 534, 143, 58, 315, 628, 712, 670, 273, 446, 231, 357, 100, 15, 586, 186, 489, 401, 402, 490] 1 [6.0, 7.0, 8.0, 56.0, 57.0, 58.0, 105.0, 106.0, 107.0, 155.0, 156.0, 157.0, 204.0, 205.0, 206.0, 257.0, 258.0, 259.0, 306.0, 307.0, 308.0, 355.0, 356.0, 357.0, 404.0, 405.0, 406.0, 454.0, 455.0, 456.0, 507.0, 508.0, 509.0, 556.0, 557.0, 558.0, 609.0, 610.0, 611.0, 657.0, 658.0, 659.0, 671.0, 672.0, 673.0, 720.0, 721.0, 722.0, 769.0, 770.0, 771.0, 818.0, 819.0, 820.0, 867.0, 868.0, 869.0]\n",
      "[592, 770, 143, 58, 320, 686, 278, 728, 644, 451, 236, 362, 100, 15, 550, 186, 494, 406, 187, 407] 1 [6.0, 7.0, 8.0, 56.0, 57.0, 58.0, 105.0, 106.0, 107.0, 155.0, 156.0, 157.0, 204.0, 205.0, 206.0, 263.0, 264.0, 265.0, 312.0, 313.0, 314.0, 361.0, 362.0, 363.0, 410.0, 411.0, 412.0, 460.0, 461.0, 462.0, 513.0, 514.0, 515.0, 562.0, 563.0, 564.0, 614.0, 615.0, 616.0, 629.0, 630.0, 631.0, 678.0, 679.0, 680.0, 739.0, 740.0, 741.0, 788.0, 789.0, 790.0, 837.0, 838.0, 839.0, 886.0, 887.0, 888.0]\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 1 [12.0, 13.0, 14.0]\n",
      "[] 0 0\n",
      "[764, 586, 63, 148, 325, 680, 722, 283, 15, 456, 241, 544, 367, 105, 638, 191, 499, 411, 192, 412] 1 [6.0, 7.0, 8.0, 62.0, 63.0, 64.0, 111.0, 112.0, 113.0, 161.0, 162.0, 163.0, 210.0, 211.0, 212.0, 269.0, 270.0, 271.0, 318.0, 319.0, 320.0, 367.0, 368.0, 369.0, 416.0, 417.0, 418.0, 466.0, 467.0, 468.0, 519.0, 520.0, 521.0, 568.0, 569.0, 570.0, 621.0, 622.0, 623.0, 670.0, 671.0, 672.0, 718.0, 719.0, 720.0, 732.0, 733.0, 734.0, 781.0, 782.0, 783.0, 830.0, 831.0, 832.0, 879.0, 880.0, 881.0]\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[24, 25, 26, 27, 28, 29, 30, 23, 22, 21] 1 [26.0, 27.0, 28.0]\n",
      "[] 0 0\n",
      "[] 1 [12.0, 13.0, 14.0]\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[754, 143, 446, 58, 315, 712, 670, 628, 586, 273, 544, 231, 357, 100, 15, 186, 401, 402, 187, 499] 1 [6.0, 7.0, 8.0, 56.0, 57.0, 58.0, 105.0, 106.0, 107.0, 155.0, 156.0, 157.0, 204.0, 205.0, 206.0, 257.0, 258.0, 259.0, 306.0, 307.0, 308.0, 355.0, 356.0, 357.0, 404.0, 405.0, 406.0, 454.0, 455.0, 456.0, 507.0, 508.0, 509.0, 569.0, 570.0, 571.0, 622.0, 623.0, 624.0, 671.0, 672.0, 673.0, 720.0, 721.0, 722.0, 769.0, 770.0, 771.0, 818.0, 819.0, 820.0, 867.0, 868.0, 869.0]\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[13, 14, 15, 16, 17, 18, 19, 20, 12, 11] 1 [13.0, 14.0, 15.0]\n",
      "[755, 315, 143, 58, 587, 671, 629, 273, 713, 457, 545, 231, 100, 15, 368, 186, 500, 412, 413, 501] 1 [6.0, 7.0, 8.0, 56.0, 57.0, 58.0, 105.0, 106.0, 107.0, 155.0, 156.0, 157.0, 204.0, 205.0, 206.0, 257.0, 258.0, 259.0, 306.0, 307.0, 308.0, 355.0, 356.0, 357.0, 418.0, 419.0, 420.0, 468.0, 469.0, 470.0, 521.0, 522.0, 523.0, 570.0, 571.0, 572.0, 623.0, 624.0, 625.0, 672.0, 673.0, 674.0, 721.0, 722.0, 723.0, 770.0, 771.0, 772.0, 819.0, 820.0, 821.0, 868.0, 869.0, 870.0]\n",
      "[4] 1 [5.0, 6.0, 7.0]\n",
      "[] 0 0\n",
      "[84, 85, 86, 88, 87, 89, 90, 83] 1 [96.0, 97.0, 98.0]\n",
      "[] 0 0\n",
      "[769, 63, 153, 335, 601, 293, 685, 643, 727, 15, 471, 559, 377, 110, 251, 421, 196, 514, 422, 515] 1 [6.0, 7.0, 8.0, 62.0, 63.0, 64.0, 117.0, 118.0, 119.0, 167.0, 168.0, 169.0, 216.0, 217.0, 218.0, 268.0, 269.0, 270.0, 282.0, 283.0, 284.0, 331.0, 332.0, 333.0, 380.0, 381.0, 382.0, 429.0, 430.0, 431.0, 479.0, 480.0, 481.0, 538.0, 539.0, 540.0, 587.0, 588.0, 589.0, 640.0, 641.0, 642.0, 689.0, 690.0, 691.0, 738.0, 739.0, 740.0, 787.0, 788.0, 789.0, 836.0, 837.0, 838.0, 885.0, 886.0, 887.0]\n",
      "[] 0 0\n",
      "[] 1 [12.0, 13.0, 14.0]\n",
      "[60, 61, 62, 63, 64, 65, 66, 59, 58, 57, 56] 1 [70.0, 71.0, 72.0]\n",
      "[754, 576, 143, 58, 315, 670, 273, 712, 446, 534, 231, 357, 100, 15, 628, 186, 489, 401, 402, 490] 1 [6.0, 7.0, 8.0, 56.0, 57.0, 58.0, 105.0, 106.0, 107.0, 155.0, 156.0, 157.0, 204.0, 205.0, 206.0, 257.0, 258.0, 259.0, 306.0, 307.0, 308.0, 355.0, 356.0, 357.0, 404.0, 405.0, 406.0, 454.0, 455.0, 456.0, 507.0, 508.0, 509.0, 556.0, 557.0, 558.0, 609.0, 610.0, 611.0, 658.0, 659.0, 660.0, 720.0, 721.0, 722.0, 769.0, 770.0, 771.0, 818.0, 819.0, 820.0, 867.0, 868.0, 869.0]\n",
      "[50, 51, 52, 53, 54, 55, 56, 49] 1 [55.0, 56.0, 57.0]\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[14, 15, 16, 17, 18, 19, 20, 13, 12, 11] 1 [21.0, 22.0, 23.0]\n",
      "[] 0 0\n",
      "[] 1 [4.0, 5.0, 6.0]\n",
      "TP:31 FP:1 FN:8 TN:88\n",
      "TP_l:23 FP_l:1 FN_l:16 TN_l:88\n",
      "epochs: 2\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[53, 54, 55, 56, 57, 58, 59, 62, 60, 61, 67, 66, 63, 72, 68, 64, 71, 73, 65, 69] 1 [61.0, 62.0, 63.0]\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 1 [12.0, 13.0, 14.0]\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 1 [18.0, 19.0, 20.0]\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[764, 581, 143, 58, 315, 680, 273, 722, 451, 539, 231, 357, 100, 15, 638, 401, 186, 494, 402, 495] 1 [6.0, 7.0, 8.0, 56.0, 57.0, 58.0, 105.0, 106.0, 107.0, 155.0, 156.0, 157.0, 204.0, 205.0, 206.0, 257.0, 258.0, 259.0, 306.0, 307.0, 308.0, 355.0, 356.0, 357.0, 404.0, 405.0, 406.0, 454.0, 455.0, 456.0, 513.0, 514.0, 515.0, 562.0, 563.0, 564.0, 615.0, 616.0, 617.0, 664.0, 665.0, 666.0, 732.0, 733.0, 734.0, 781.0, 782.0, 783.0, 830.0, 831.0, 832.0, 879.0, 880.0, 881.0]\n",
      "[] 1 [4.0, 5.0, 6.0]\n",
      "[52, 53, 54, 55, 56, 57, 58, 59, 51] 1 [51.0, 52.0, 53.0]\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[36, 37, 38, 39, 40, 41, 42, 43, 44, 35, 34] 1 [36.0, 37.0, 38.0]\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[50, 51, 52, 53, 54, 55, 56, 49] 1 [55.0, 56.0, 57.0]\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 1 [12.0, 13.0, 14.0]\n",
      "[] 0 0\n",
      "[764, 362, 143, 456, 58, 320, 596, 722, 680, 638, 278, 236, 554, 100, 15, 186, 411, 187, 412, 509] 1 [6.0, 7.0, 8.0, 56.0, 57.0, 58.0, 105.0, 106.0, 107.0, 155.0, 156.0, 157.0, 204.0, 205.0, 206.0, 263.0, 264.0, 265.0, 312.0, 313.0, 314.0, 361.0, 362.0, 363.0, 410.0, 411.0, 412.0, 466.0, 467.0, 468.0, 519.0, 520.0, 521.0, 567.0, 568.0, 569.0, 581.0, 582.0, 583.0, 634.0, 635.0, 636.0, 683.0, 684.0, 685.0, 732.0, 733.0, 734.0, 781.0, 782.0, 783.0, 830.0, 831.0, 832.0, 879.0, 880.0, 881.0]\n",
      "[] 1 [10.0, 11.0, 12.0]\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[68, 69, 70, 71, 72, 73, 74, 75, 67] 1 [73.0, 74.0, 75.0]\n",
      "[764, 320, 100, 148, 58, 596, 278, 722, 680, 638, 466, 554, 236, 15, 372, 421, 509, 191, 510, 192] 1 [6.0, 7.0, 8.0, 56.0, 57.0, 58.0, 105.0, 106.0, 107.0, 161.0, 162.0, 163.0, 210.0, 211.0, 212.0, 263.0, 264.0, 265.0, 312.0, 313.0, 314.0, 361.0, 362.0, 363.0, 423.0, 424.0, 425.0, 479.0, 480.0, 481.0, 532.0, 533.0, 534.0, 581.0, 582.0, 583.0, 634.0, 635.0, 636.0, 683.0, 684.0, 685.0, 732.0, 733.0, 734.0, 781.0, 782.0, 783.0, 830.0, 831.0, 832.0, 879.0, 880.0, 881.0]\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[759, 283, 153, 68, 591, 330, 675, 633, 717, 461, 241, 549, 372, 110, 25, 504, 416, 196, 417, 505] 1 [19.0, 20.0, 21.0, 69.0, 70.0, 71.0, 118.0, 119.0, 120.0, 168.0, 169.0, 170.0, 217.0, 218.0, 219.0, 270.0, 271.0, 272.0, 319.0, 320.0, 321.0, 374.0, 375.0, 376.0, 423.0, 424.0, 425.0, 473.0, 474.0, 475.0, 526.0, 527.0, 528.0, 575.0, 576.0, 577.0, 628.0, 629.0, 630.0, 677.0, 678.0, 679.0, 726.0, 727.0, 728.0, 775.0, 776.0, 777.0, 824.0, 825.0, 826.0, 873.0, 874.0, 875.0]\n",
      "[] 0 0\n",
      "[91, 92, 93, 94, 95, 96, 98, 97, 90] 1 [96.0, 97.0, 98.0]\n",
      "[] 0 0\n",
      "[754, 58, 325, 586, 670, 628, 283, 712, 456, 544, 241, 100, 367, 15, 153, 196, 499, 411, 412, 197] 1 [6.0, 7.0, 8.0, 56.0, 57.0, 58.0, 105.0, 106.0, 107.0, 168.0, 169.0, 170.0, 217.0, 218.0, 219.0, 270.0, 271.0, 272.0, 319.0, 320.0, 321.0, 368.0, 369.0, 370.0, 417.0, 418.0, 419.0, 467.0, 468.0, 469.0, 520.0, 521.0, 522.0, 569.0, 570.0, 571.0, 622.0, 623.0, 624.0, 671.0, 672.0, 673.0, 720.0, 721.0, 722.0, 769.0, 770.0, 771.0, 818.0, 819.0, 820.0, 867.0, 868.0, 869.0]\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[28, 29, 30, 31, 32, 33, 34, 27, 26, 25, 24, 23] 1 [33.0, 34.0, 35.0]\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[] 0 0\n",
      "[754, 143, 58, 315, 586, 712, 670, 628, 273, 446, 231, 357, 100, 15, 544, 489, 186, 401, 402, 187] 1 [6.0, 7.0, 8.0, 56.0, 57.0, 58.0, 105.0, 106.0, 107.0, 155.0, 156.0, 157.0, 204.0, 205.0, 206.0, 257.0, 258.0, 259.0, 306.0, 307.0, 308.0, 355.0, 356.0, 357.0, 404.0, 405.0, 406.0, 454.0, 455.0, 456.0, 507.0, 508.0, 509.0, 556.0, 557.0, 558.0, 608.0, 609.0, 610.0, 622.0, 623.0, 624.0, 671.0, 672.0, 673.0, 720.0, 721.0, 722.0, 769.0, 770.0, 771.0, 818.0, 819.0, 820.0, 867.0, 868.0, 869.0]\n",
      "[10, 11, 9, 12, 8, 13, 14, 16, 15, 17, 18, 19, 7, 20, 21, 6, 5] 1 [12.0, 13.0, 14.0]\n",
      "[] 1 [7.0, 8.0, 9.0]\n",
      "[19, 21, 20, 18, 22, 23, 24, 17, 25, 32, 27, 31, 26, 28, 33, 30, 29, 16] 1 [18.0, 19.0, 20.0]\n",
      "TP:46 FP:1 FN:14 TN:131\n",
      "TP_l:37 FP_l:1 FN_l:23 TN_l:131\n",
      "TP:46 FP:1 FN:14 TN:131\n",
      "\n",
      "FPR: 0.007575757575757576\n",
      "\n",
      "FNR: 0.23333333333333334\n",
      "\n",
      "accuracy: 0.921875\n",
      "\n",
      "precision: 0.9787234042553191\n",
      "\n",
      "recall: 0.7666666666666667\n",
      "\n",
      "F1_score: 0.8598130841121495\n",
      "\n",
      "\n",
      "TP_l:37 FP_l:1 FN_l:23 TN:131\n",
      "\n",
      "FPR_location: 0.007575757575757576\n",
      "\n",
      "FNR_location: 0.38333333333333336\n",
      "\n",
      "accuracy_location: 0.875\n",
      "\n",
      "precision_location: 0.9736842105263158\n",
      "\n",
      "recall_location: 0.6166666666666667\n",
      "\n",
      "F1_score_location: 0.7551020408163265\n",
      "\n",
      "\n",
      "loU: 0.11310239789158677\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_predict_line(value_sequence, threshold_value=0.5):\n",
    "    value_sequence = list(np.array(value_sequence))\n",
    "    vs = len(value_sequence) - 1\n",
    "    while value_sequence[vs] == value_sequence[-1]:\n",
    "        vs -= 1\n",
    "    value_sequence = value_sequence[:vs + 2]\n",
    "    # print(value_sequence)\n",
    "    dict={}\n",
    "    for i in range(len(value_sequence)):\n",
    "        dict[i]=value_sequence[i]\n",
    "    # print(dict)\n",
    "    #按照value_sequence值大小排序\n",
    "    dict=sorted(dict.items(), key = lambda kv:(kv[1], kv[0]),reverse=True)\n",
    "    # print(dict)\n",
    "    predict_line = []\n",
    "    t=0\n",
    "    for d in dict:\n",
    "        t+=1\n",
    "        if t>20:\n",
    "            break\n",
    "        if d[1] > threshold_value:\n",
    "            predict_line.append(d[0])\n",
    "    return predict_line\n",
    "\n",
    "\n",
    "def test_model(model, datapath, labelpath, result_path):\n",
    "    TP, TN, FP, FN = 0, 0, 0, 0\n",
    "    TP_l, TN_l, FP_l, FN_l = 0, 0, 0, 0\n",
    "    loU_list = []\n",
    "    partial_model = Model(inputs=model.layers[0].input, outputs=model.layers[8].output)\n",
    "    test_data = TestDataGenerator(datapath, labelpath, batch_size=64)\n",
    "    batch_size = 64\n",
    "    iter_num = 92\n",
    "    for i in range(3):\n",
    "        print(\"epochs: \" + str(i))\n",
    "        td = next(test_data)\n",
    "        output_test = partial_model([td[0][0]], training=False)\n",
    "        label = td[1]\n",
    "        vul_line = td[2]\n",
    "        # print(output_test.shape,label.shape,len(vul_line))\n",
    "        for j in range(batch_size):\n",
    "            predict_line = get_predict_line(output_test[j])\n",
    "            print(predict_line,label[j],vul_line[j])\n",
    "            # print(output_test[i])\n",
    "            # print(predict_line)\n",
    "            # print(label[j])\n",
    "            if predict_line:\n",
    "                label_pred = 1\n",
    "            else:\n",
    "                label_pred = 0\n",
    "            # print(label_pred,label[j])\n",
    "            if label_pred == 0 and label[j] == 0:\n",
    "                TN += 1\n",
    "                TN_l += 1\n",
    "            if label_pred == 0 and label[j] == 1:\n",
    "                FN += 1\n",
    "                FN_l += 1\n",
    "            if label_pred == 1 and label[j] == 0:\n",
    "                FP += 1\n",
    "                FP_l += 1\n",
    "            if label_pred == 1 and label[j] == 1:\n",
    "                TP += 1\n",
    "                flag_l = False\n",
    "                for pred in predict_line:\n",
    "                    if pred in vul_line[j]:\n",
    "                        flag_l = True\n",
    "                        break\n",
    "                if flag_l:\n",
    "                    TP_l += 1\n",
    "                else:\n",
    "                    FN_l += 1\n",
    "                overlap_line = list(set(predict_line).intersection(set(vul_line[j])))\n",
    "                union_line = list(set(predict_line).union(set(vul_line[j])))\n",
    "                loU = len(overlap_line) / len(union_line)\n",
    "                loU_list.append(loU)\n",
    "        print('TP:' + str(TP) + ' FP:' + str(FP) + ' FN:' + str(FN) + ' TN:' + str(TN))\n",
    "        print('TP_l:' + str(TP_l) + ' FP_l:' + str(FP_l) + ' FN_l:' + str(FN_l) + ' TN_l:' + str(TN_l))\n",
    "    FPR = FP / (FP + TN)\n",
    "    FNR = FN / (TP + FN)\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    F1_score = (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "    FPR_line = FP_l / (FP_l + TN_l)\n",
    "    FNR_line = FN_l / (TP_l + FN_l)\n",
    "    accuracy_line = (TP_l + TN_l) / (TP_l + FP_l + FN_l + TN_l)\n",
    "    precision_line = TP_l / (TP_l + FP_l)\n",
    "    recall_line = TP_l / (TP_l + FN_l)\n",
    "    F1_score_line = (2 * precision_line * recall_line) / (precision_line + recall_line)\n",
    "\n",
    "    loU = np.mean(loU_list)\n",
    "    # print('test_samples_num: ' + str(len(data)) + '\\n')\n",
    "    print('TP:' + str(TP) + ' FP:' + str(FP) + ' FN:' + str(FN) + ' TN:' + str(TN) + '\\n')\n",
    "    print('FPR: ' + str(FPR) + '\\n')\n",
    "    print('FNR: ' + str(FNR) + '\\n')\n",
    "    print('accuracy: ' + str(accuracy) + '\\n')\n",
    "    print('precision: ' + str(precision) + '\\n')\n",
    "    print('recall: ' + str(recall) + '\\n')\n",
    "    print('F1_score: ' + str(F1_score) + '\\n\\n')\n",
    "\n",
    "    print('TP_l:' + str(TP_l) + ' FP_l:' + str(FP_l) + ' FN_l:' + str(FN_l) + ' TN:' + str(TN_l) + '\\n')\n",
    "    print('FPR_location: ' + str(FPR_line) + '\\n')\n",
    "    print('FNR_location: ' + str(FNR_line) + '\\n')\n",
    "    print('accuracy_location: ' + str(accuracy_line) + '\\n')\n",
    "    print('precision_location: ' + str(precision_line) + '\\n')\n",
    "    print('recall_location: ' + str(recall_line) + '\\n')\n",
    "    print('F1_score_location: ' + str(F1_score_line) + '\\n\\n')\n",
    "\n",
    "    print('loU: ' + str(loU) + '\\n')\n",
    "\n",
    "    with open(result_path, 'a') as fwrite:\n",
    "        # fwrite.write('test_samples_num: ' + str(len(data)) + '\\n')\n",
    "        fwrite.write('TP:' + str(TP) + ' FP:' + str(FP) + ' FN:' + str(FN) + ' TN:' + str(TN) + '\\n')\n",
    "        fwrite.write('FPR: ' + str(FPR) + '\\n')\n",
    "        fwrite.write('FNR: ' + str(FNR) + '\\n')\n",
    "        fwrite.write('accuracy: ' + str(accuracy) + '\\n')\n",
    "        fwrite.write('precision: ' + str(precision) + '\\n')\n",
    "        fwrite.write('recall: ' + str(recall) + '\\n')\n",
    "        fwrite.write('F1_score: ' + str(F1_score) + '\\n\\n')\n",
    "\n",
    "        fwrite.write('TP_l:' + str(TP_l) + ' FP_l:' + str(FP_l) + ' FN_l:' + str(FN_l) + ' TN:' + str(TN_l) + '\\n')\n",
    "        fwrite.write('FPR_location: ' + str(FPR_line) + '\\n')\n",
    "        fwrite.write('FNR_location: ' + str(FNR_line) + '\\n')\n",
    "        fwrite.write('accuracy_location: ' + str(accuracy_line) + '\\n')\n",
    "        fwrite.write('precision_location: ' + str(precision_line) + '\\n')\n",
    "        fwrite.write('recall_location: ' + str(recall_line) + '\\n')\n",
    "        fwrite.write('F1_score_location: ' + str(F1_score_line) + '\\n\\n')\n",
    "\n",
    "        fwrite.write('loU: ' + str(loU) + '\\n')\n",
    "\n",
    "\n",
    "modelPath = './model2/model_09-0.95.h5'\n",
    "resultPath = './result/result_model_09_0.95_validation.txt'\n",
    "\n",
    "# test_IR_path = '../data/Juliet/test_IR.txt'\n",
    "# test_label_path = '../data/Juliet/test_label.txt'\n",
    "test_IR_path = '../data/Juliet/validation_IR.txt'\n",
    "test_label_path = '../data/Juliet/validation_label.txt'\n",
    "\n",
    "model = models.load_model(modelPath)\n",
    "test_model(model, test_IR_path, test_label_path, resultPath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    " ## cs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 模型中间结果测试"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "(64, 1000, 1) (64,) 64\n"
     ]
    }
   ],
   "source": [
    "modelPath = './model2/model_09-0.95.h5'\n",
    "\n",
    "test_IR_path = '../data/Juliet/test_IR.txt'\n",
    "test_label_path = '../data/Juliet/test_label.txt'\n",
    "model = models.load_model(modelPath)\n",
    "\n",
    "test_data = TestDataGenerator(test_IR_path, test_label_path, batch_size=64)\n",
    "td = next(test_data)\n",
    "partial_model = Model(inputs=model.layers[0].input, outputs=model.layers[8].output)\n",
    "output_test = partial_model([td[0][0]], training=False)\n",
    "label = td[1]\n",
    "vul_line = td[2]\n",
    "print(output_test.shape, label.shape, len(vul_line))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.04940239]\n",
      " [0.04741302]\n",
      " [0.0427826 ]\n",
      " [0.0496155 ]\n",
      " [0.05577952]\n",
      " [0.05368701]\n",
      " [0.13170964]\n",
      " [0.9797673 ]\n",
      " [0.9982405 ]\n",
      " [0.9979354 ]\n",
      " [0.9975699 ]\n",
      " [0.9967884 ]\n",
      " [0.9962789 ]\n",
      " [0.9956728 ]\n",
      " [0.9949349 ]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]\n",
      " [0.14615348]], shape=(1000, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(output_test[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13, 14, 15, 16, 17, 18, 19, 20, 21, 12, 11]\n"
     ]
    }
   ],
   "source": [
    "print(get_predict_line(output_test[6]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "按值(value)排序:\n",
      "[(3, 323), (2, 56), (4, 24), (6, 18), (5, 12), (1, 2)]\n",
      "3 323\n",
      "2 56\n",
      "4 24\n",
      "6 18\n",
      "5 12\n",
      "1 2\n"
     ]
    }
   ],
   "source": [
    "def dictionairy():\n",
    "\n",
    "    # 声明字典\n",
    "    key_value ={}\n",
    "\n",
    "    # 初始化\n",
    "    key_value[2] = 56\n",
    "    key_value[1] = 2\n",
    "    key_value[5] = 12\n",
    "    key_value[4] = 24\n",
    "    key_value[6] = 18\n",
    "    key_value[3] = 323\n",
    "\n",
    "\n",
    "    print (\"按值(value)排序:\")\n",
    "    dict=sorted(key_value.items(), key = lambda kv:(kv[1], kv[0]),reverse=True)\n",
    "    print(dict)\n",
    "    for i in dict:\n",
    "        print(i[0],i[1])\n",
    "dictionairy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 1 0 0 1 1 0 0 1 0 1 1 0 0 0 0 1 0 0\n",
      " 0 1 0 0 0 1 1 0 0 0 1 0 1 0 0 0 1 1 1 0 0 0 1 0 0 1 1]\n",
      "0\n",
      "[754, 58, 325, 586, 670, 628, 283, 712, 456, 544]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(label)\n",
    "print(vul_line[4])\n",
    "# print(output_test[1])\n",
    "predict_line = get_predict_line(output_test[7])\n",
    "print(predict_line)\n",
    "if predict_line:\n",
    "    label_pred = 1\n",
    "else:\n",
    "    label_pred = 0\n",
    "print(label_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 模型最终结果显示"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [6]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m td \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(\u001B[43mtest_data\u001B[49m)\n\u001B[0;32m      2\u001B[0m output \u001B[38;5;241m=\u001B[39m model([td[\u001B[38;5;241m0\u001B[39m]], training\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m      3\u001B[0m label \u001B[38;5;241m=\u001B[39m td[\u001B[38;5;241m1\u001B[39m]\n",
      "\u001B[1;31mNameError\u001B[0m: name 'test_data' is not defined"
     ]
    }
   ],
   "source": [
    "td = next(test_data)\n",
    "output = model([td[0]], training=False)\n",
    "label = td[1]\n",
    "print(label)\n",
    "print(output)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "  9/100 [=>............................] - ETA: 4:04 - loss: 0.1923 - accuracy: 0.9306 - precision: 0.9638 - recall: 0.7917 - true_positives: 133.0000 - true_negatives: 403.0000 - false_positives: 5.0000 - false_negatives: 35.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [12]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m test_data2\u001B[38;5;241m=\u001B[39mDataGenerator(test_IR_path,test_label_path,batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m64\u001B[39m)\n\u001B[1;32m----> 2\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_data2\u001B[49m\u001B[43m,\u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m64\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43msteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\program_files\\miniconda3\\envs\\DeepLearning\\lib\\site-packages\\keras\\engine\\training.py:1501\u001B[0m, in \u001B[0;36mModel.evaluate\u001B[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001B[0m\n\u001B[0;32m   1499\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m'\u001B[39m, step_num\u001B[38;5;241m=\u001B[39mstep, _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m   1500\u001B[0m   callbacks\u001B[38;5;241m.\u001B[39mon_test_batch_begin(step)\n\u001B[1;32m-> 1501\u001B[0m   tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtest_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1502\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   1503\u001B[0m     context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32mD:\\program_files\\miniconda3\\envs\\DeepLearning\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:885\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    882\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    884\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 885\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    887\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    888\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32mD:\\program_files\\miniconda3\\envs\\DeepLearning\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:924\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    921\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    922\u001B[0m \u001B[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001B[39;00m\n\u001B[0;32m    923\u001B[0m \u001B[38;5;66;03m# run the first trace but we should fail if variables are created.\u001B[39;00m\n\u001B[1;32m--> 924\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_stateful_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    925\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_created_variables \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001B[0;32m    926\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCreating variables on a non-first call to a function\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    927\u001B[0m                    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m decorated with tf.function.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mD:\\program_files\\miniconda3\\envs\\DeepLearning\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3039\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   3036\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m   3037\u001B[0m   (graph_function,\n\u001B[0;32m   3038\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[1;32m-> 3039\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   3040\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\program_files\\miniconda3\\envs\\DeepLearning\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1963\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1959\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1960\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1961\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1962\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1963\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1964\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m   1965\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1966\u001B[0m     args,\n\u001B[0;32m   1967\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1968\u001B[0m     executing_eagerly)\n\u001B[0;32m   1969\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32mD:\\program_files\\miniconda3\\envs\\DeepLearning\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    589\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    590\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 591\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    592\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    593\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    594\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    595\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    596\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    597\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    598\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m    599\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[0;32m    600\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    603\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[0;32m    604\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[1;32mD:\\program_files\\miniconda3\\envs\\DeepLearning\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     57\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     58\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 59\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     60\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     61\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     62\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "test_data2 = TrainDataGenerator(test_IR_path, test_label_path, batch_size=64)\n",
    "model.evaluate(test_data2, batch_size=64, steps=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Predict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processing progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21834705/21834705 [00:00<00:00, 31180411.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []]\n"
     ]
    }
   ],
   "source": [
    "def loadData(datapath):\n",
    "    irLine = []  # 每行ir向量\n",
    "    irList = []  # ir切片向量列表\n",
    "    print('Data processing progress:')\n",
    "    # 打开文件：以二进制读模式、utf-8格式的编码方式打开\n",
    "    with tqdm(total=os.path.getsize(datapath)) as pbar:\n",
    "        with open(datapath, 'r', encoding='utf-8') as frData:\n",
    "            for line in frData:\n",
    "                pbar.update(len(line))\n",
    "                # 逐行遍历：行内字段按'\\t'分隔符分隔，转换为列表\n",
    "                line = line.strip()\n",
    "                a = line.split('\\t')\n",
    "                if '#' not in a[0]:\n",
    "                    a = list(map(float, a))\n",
    "                    irLine.append(a)\n",
    "                else:\n",
    "                    x = [0 for i in range(300)]\n",
    "                    while len(irLine) < 1000:\n",
    "                        irLine.append(x)\n",
    "                    irList.append(irLine)\n",
    "                    irLine = []\n",
    "                    continue\n",
    "    return np.array(irList)\n",
    "\n",
    "def get_predict_line(value_sequence, threshold_value=0.5):\n",
    "    value_sequence = list(np.array(value_sequence))\n",
    "    vs = len(value_sequence) - 1\n",
    "    while value_sequence[vs] == value_sequence[-1]:\n",
    "        vs -= 1\n",
    "    value_sequence = value_sequence[:vs + 2]\n",
    "    # print(value_sequence)\n",
    "    dict={}\n",
    "    for i in range(len(value_sequence)):\n",
    "        dict[i]=value_sequence[i]\n",
    "    # print(dict)\n",
    "    #按照value_sequence值大小排序\n",
    "    dict=sorted(dict.items(), key = lambda kv:(kv[1], kv[0]),reverse=True)\n",
    "    # print(dict)\n",
    "    predict_line = []\n",
    "    t=0\n",
    "    for d in dict:\n",
    "        t+=1\n",
    "        if t>20:\n",
    "            break\n",
    "        if d[1] > threshold_value:\n",
    "            predict_line.append(d[0])\n",
    "    return predict_line\n",
    "\n",
    "\n",
    "def model_predict(model, datapath):\n",
    "    data=loadData(datapath)\n",
    "    partial_model = Model(inputs=model.layers[0].input, outputs=model.layers[8].output)\n",
    "    output_test = partial_model([data], training=False)\n",
    "    # print(output_test.shape)\n",
    "    predict_line=[]\n",
    "    for j in range(output_test.shape[0]):\n",
    "        predict_line.append(get_predict_line(output_test[j]))\n",
    "    return predict_line\n",
    "\n",
    "\n",
    "modelPath = './model2/model_09-0.95.h5'\n",
    "\n",
    "test_IR_path = '../data/data2.txt'\n",
    "\n",
    "model = models.load_model(modelPath)\n",
    "result=model_predict(model, test_IR_path)\n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dab8e41921a9804032d7b1bd163ac623c44de801f9b5a9764714bd0c64231e68"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}